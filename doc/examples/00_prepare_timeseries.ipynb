{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e901f921",
   "metadata": {},
   "source": [
    "# Preprocessing user-provided time series\n",
    "*Developed by D. Brakenhoff, Artesia, and R.A. Collenteur, Eawag, January (2021-2023)*\n",
    "\n",
    "This notebooks shows how to solve the most common errors that arise during the validation of the user provided time series. After showing how to deal with some of the easier errors, we will dive into the topic of making time series equidistant. For this purpose Pastas contains a lot of helper functions.   \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note</b> \n",
    "To see the Error messages returned by `validate_series` method, you have to uncomment the code-line. This is done to make sure the notebook still runs automatically for our Documentation website.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c439993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pastas as ps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ps.show_versions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7318278d",
   "metadata": {},
   "source": [
    "## 1. Validating the time series, what is checked?\n",
    "\n",
    "Let us first look at the docstring of the `ps.validate_stress` method, which can be used to automatically check user-provided input time series. This method is also ud internally in Pastas to check all user provided time series. For the stresses `ps.validate_stress` is used and for the oseries the `ps.validate_oseries` is used. The only difference between these methods is that the oseries are not checked for equidistant time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ps.validate_stress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626071f4",
   "metadata": {},
   "source": [
    "### a. If the time series is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(\"2000-01-01\", \"2000-01-10\")\n",
    "series = pd.DataFrame(data=[np.arange(10.0)], index=index)\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.iloc[:, 0]  # Simpy select the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78c299",
   "metadata": {},
   "source": [
    "### b. If values are not floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acf137",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(\"2000-01-01\", \"2000-01-10\")\n",
    "series = pd.Series(data=range(10), index=index, name=\"Stress\")\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a possible fix to this issue\n",
    "series = series.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173f0ac",
   "metadata": {},
   "source": [
    "### c. If the index is not a datetimeindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff81fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(data=np.arange(10.0), index=range(10), name=\"Stress\")\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a possible fix to this issue\n",
    "series.index = pd.to_datetime(series.index)\n",
    "ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513fe6b",
   "metadata": {},
   "source": [
    "### d. If index is not monotonically increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.to_datetime([\"2000-01-01\", \"2000-01-03\", \"2000-01-02\", \"2000-01-4\"])\n",
    "series = pd.Series(data=np.arange(4.0), index=index, name=\"Stress\")\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a possible fix to this issue\n",
    "series = series.sort_index()\n",
    "ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb3c37",
   "metadata": {},
   "source": [
    "### e. If the index has duplicate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.to_datetime([\"2000-01-01\", \"2000-01-02\", \"2000-01-02\", \"2000-01-3\"])\n",
    "series = pd.Series(data=np.arange(4.0), index=index, name=\"Stress\")\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a possible fix to this issue\n",
    "grouped = series.groupby(level=0)\n",
    "series = grouped.mean()\n",
    "ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c1724",
   "metadata": {},
   "source": [
    "### f. If the time series has nan-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8244e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(\"2000-01-01\", \"2000-01-10\")\n",
    "series = pd.Series(data=np.arange(10.0), index=index, name=\"Stress\")\n",
    "series.loc[\"2000-01-05\"] = np.nan\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "ps.validate_stress(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a possible fix to this issue for oseries\n",
    "series.dropna()  # simply drop the nan-values\n",
    "\n",
    "# Here is a possible fix to this issue for stresses\n",
    "series = series.fillna(series.mean())  # For example for water levels\n",
    "series = series.fillna(0.0)  # For example for precipitation\n",
    "series = series.interpolate(method=\"time\")  # For example for evaporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a362629",
   "metadata": {},
   "source": [
    "## 2. If a stress time series has non-equidistant time steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries\n",
    "freq = \"6H\"\n",
    "idx0 = pd.date_range(\"2000-01-01\", freq=freq, periods=7).tolist()\n",
    "idx0[0] = pd.Timestamp(\"2000-01-01 04:00:00\")\n",
    "idx0[-1] = pd.Timestamp(\"2000-01-02 11:00:00\")\n",
    "series = pd.Series(index=idx0, data=np.arange(len(idx0), dtype=float), name=\"Stress\")\n",
    "\n",
    "# Here's error message return by Pastas\n",
    "# ps.validate_stress(series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0395b960",
   "metadata": {},
   "source": [
    "Pastas contains some convenience functions for creating equidistant time series. The method for creating an equidistant time series depends on the type of stress and different methods are used for levels (e.g. head, water levels) than for fluxes (e.g. precipitation, evaporation, pumping discharge). These methods are presented in the next sections.\n",
    "\n",
    "\n",
    "### Creating equidistant time series for levels\n",
    "\n",
    "The following methods are used for time series that do not need to be resampled. The measurements represent a state (e.g. head, water level) and either an equidistant sample is derived from the original time series or observations are shifted slightly to create an equidistant time series. This can be done in a number of different ways:\n",
    "\n",
    "- `pandas_equidistant_sample` takes a sample at equidistant timesteps from the original series, at the user-specified frequency. For very irregular time series lots of observations will be lost. The advantage is that observations are not shifted in time, unlike in the other methods.\n",
    "- `pandas_equidistant_nearest` creates a new equidistant index with the user-specified frequency, then `Series.reindex()` is used with `method=\"nearest\"` which will shift certain observations in time to fill the equidistant time series. This method can introduce duplicates (i.e. an observation that is used more than once) in the final result.\n",
    "- `pandas_equidistant_asfreq` rounds the series index to the user-specified frequency, then drops any duplicates before calling `Series.asfreq` with the user-specified frequency. This ensures no duplicates are contained in the resulting time series.\n",
    "- `get_equidistant_timeseries` creates a equidistant time series minimizing the number of dropped points and ensuring that each observation from the original time series is used only once in the resulting equidistant time series. This method \n",
    "\n",
    "\n",
    "The different methods are compared in the following four examples.\n",
    "\n",
    "_**Note:** in terms of performance the pandas methods are much faster._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb59811",
   "metadata": {},
   "source": [
    "#### Example 1\n",
    "\n",
    "Lets create a timeseries spaced which is normally spaced with a frequency of 6\n",
    "hours. The first and last measurement are shifted a bit later and earlier\n",
    "respectively. \n",
    "\n",
    "The different methods for creating equidistant time series for levels are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series\n",
    "freq = \"6H\"\n",
    "idx0 = pd.date_range(\"2000-01-01\", freq=freq, periods=7).tolist()\n",
    "idx0[0] = pd.Timestamp(\"2000-01-01 04:00:00\")\n",
    "idx0[-1] = pd.Timestamp(\"2000-01-02 11:00:00\")\n",
    "series = pd.Series(index=idx0, data=np.arange(len(idx0), dtype=float))\n",
    "\n",
    "# Create equidistant time series with Pastas\n",
    "s_pd1 = ps.ts.pandas_equidistant_sample(series, freq)\n",
    "s_pd2 = ps.ts.pandas_equidistant_nearest(series, freq)\n",
    "s_pd3 = ps.ts.pandas_equidistant_asfreq(series, freq)\n",
    "s_pastas = ps.ts.get_equidistant_series(series, freq)\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = series.plot(\n",
    "    marker=\"o\",\n",
    "    label=\"original time series\",\n",
    "    ms=10,\n",
    ")\n",
    "s_pd2.plot(ax=ax, marker=\"x\", ms=8, label=\"pandas_equidistant_nearest\")\n",
    "s_pd3.plot(ax=ax, marker=\"^\", ms=8, label=\"pandas_equidistant_asfreq\")\n",
    "s_pd1.plot(ax=ax, marker=\"+\", ms=16, label=\"pandas_equidistant_sample\")\n",
    "s_pastas.plot(ax=ax, marker=\".\", label=\"get_equidistant_series\")\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8682dad5",
   "metadata": {},
   "source": [
    "Both the `pandas_equidistant_nearest` and `pandas_equidistant_asfreq` methods and `get_equidistant_series` show the observations at the beginning and the end of the time series are shifted to the nearest equidistant timestamp. The `pandas_equidistant_sample` method drops 2 datapoints because they're measured at different time offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions to show differences in performance\n",
    "def values_kept(s, original):\n",
    "    diff = set(original.dropna().values) & set(s.dropna().values)\n",
    "    return len(diff)\n",
    "\n",
    "\n",
    "def n_duplicates(s):\n",
    "    return (s.value_counts() >= 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([series, s_pd1, s_pd2, s_pd3, s_pastas], axis=1)\n",
    "dfall.columns = [\n",
    "    \"original\",\n",
    "    \"pandas_equidistant_sample\",\n",
    "    \"pandas_equidistant_nearest\",\n",
    "    \"pandas_equidistant_asfreq\",\n",
    "    \"get_equidistant_series\",\n",
    "]\n",
    "dfall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f273ac47",
   "metadata": {},
   "source": [
    "The following table summarizes the results, showing how many values from the original time series are kept and how many duplicates are contained in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431be517",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueskept = dfall.apply(values_kept, args=(dfall[\"original\"],))\n",
    "valueskept.name = \"values kept\"\n",
    "duplicates = dfall.apply(n_duplicates)\n",
    "duplicates.name = \"duplicates\"\n",
    "\n",
    "pd.concat([valueskept, duplicates], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "479436fc",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries\n",
    "freq = \"D\"\n",
    "idx0 = pd.date_range(\"2000-01-01\", freq=freq, periods=7).tolist()\n",
    "idx0[0] = pd.Timestamp(\"2000-01-01 09:00:00\")\n",
    "del idx0[2]\n",
    "del idx0[2]\n",
    "idx0[-2] = pd.Timestamp(\"2000-01-06 13:00:00\")\n",
    "idx0[-1] = pd.Timestamp(\"2000-01-06 23:00:00\")\n",
    "series = pd.Series(index=idx0, data=np.arange(len(idx0), dtype=float))\n",
    "\n",
    "# Create equidistant timeseries\n",
    "s_pd1 = ps.ts.pandas_equidistant_sample(series, freq)\n",
    "s_pd2 = ps.ts.pandas_equidistant_nearest(series, freq)\n",
    "s_pd3 = ps.ts.pandas_equidistant_asfreq(series, freq)\n",
    "s_pastas = ps.ts.get_equidistant_series(series, freq)\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = series.plot(marker=\"o\", label=\"original\", ms=10)\n",
    "s_pd2.plot(ax=ax, marker=\"x\", ms=10, label=\"pandas_equidistant_nearest\")\n",
    "s_pd3.plot(ax=ax, marker=\"^\", ms=8, label=\"pandas_equidistant_asfreq\")\n",
    "s_pd1.plot(ax=ax, marker=\"+\", ms=16, label=\"pandas_equidistant_sample\")\n",
    "s_pastas.plot(ax=ax, marker=\".\", label=\"get_equidistant_series\")\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a4fdd60",
   "metadata": {},
   "source": [
    "In this example, the shortcomings of `pandas_equidistant_nearest` are clearly visible. It duplicates observations from the original timeseries to fill the gaps. This can be solved by passing e.g. `tolerance=\"0.99{freq}\"` to `series.reindex()` in which case the gaps will not be filled. However, with very irregular timesteps this is not guaranteed to work and duplicates may still occur. The `pandas_equidistant_asfreq` and pastas methods work as expected and uses the available data to create a reasonable equidistant timeseries from the original data. The `pandas_equidistant_sample` method is only able to keep two observations from the original series in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([series, s_pd1, s_pd2, s_pd3, s_pastas], axis=1)\n",
    "dfall.columns = [\n",
    "    \"original\",\n",
    "    \"pandas_equidistant_sample\",\n",
    "    \"pandas_equidistant_nearest\",\n",
    "    \"pandas_equidistant_asfreq\",\n",
    "    \"get_equidistant_series\",\n",
    "]\n",
    "dfall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ada72be",
   "metadata": {},
   "source": [
    "The following table summarizes the results, showing how many values from the original time series are kept and how many duplicates are contained in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueskept = dfall.apply(values_kept, args=(dfall[\"original\"],))\n",
    "valueskept.name = \"values kept\"\n",
    "duplicates = dfall.apply(n_duplicates)\n",
    "duplicates.name = \"duplicates\"\n",
    "\n",
    "pd.concat([valueskept, duplicates], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5f3ad30",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries\n",
    "freq = \"2H\"\n",
    "freq2 = \"1H\"\n",
    "idx0 = pd.date_range(\"2000-01-01 18:00:00\", freq=freq, periods=3).tolist()\n",
    "idx1 = pd.date_range(\"2000-01-02 01:30:00\", freq=freq2, periods=10).tolist()\n",
    "idx0 = idx0 + idx1\n",
    "idx0[3] = pd.Timestamp(\"2000-01-02 01:31:00\")\n",
    "series = pd.Series(index=idx0, data=np.arange(len(idx0), dtype=float))\n",
    "series.iloc[8:10] = np.nan\n",
    "\n",
    "\n",
    "# Create equidistant timeseries\n",
    "s_pd1 = ps.ts.pandas_equidistant_sample(series, freq)\n",
    "s_pd2 = ps.ts.pandas_equidistant_nearest(series, freq)\n",
    "s_pd3 = ps.ts.pandas_equidistant_asfreq(series, freq)\n",
    "s_pastas1 = ps.ts.get_equidistant_series(series, freq, minimize_data_loss=True)\n",
    "s_pastas2 = ps.ts.get_equidistant_series(series, freq, minimize_data_loss=False)\n",
    "\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = series.plot(marker=\"o\", label=\"original\", ms=10)\n",
    "s_pd2.plot(ax=ax, marker=\"x\", ms=10, label=\"pandas_equidistant_nearest\")\n",
    "s_pd3.plot(ax=ax, marker=\"^\", ms=8, label=\"pandas_equidistant_asfreq\")\n",
    "s_pd1.plot(ax=ax, marker=\"+\", ms=16, label=\"pandas_equidistant_sample\")\n",
    "s_pastas1.plot(\n",
    "    ax=ax, marker=\".\", ms=6, label=\"get_equidistant_series (minimize data loss)\"\n",
    ")\n",
    "s_pastas2.plot(ax=ax, marker=\"+\", ms=10, label=\"get_equidistant_series (default)\")\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34b2daa3",
   "metadata": {},
   "source": [
    "In this example we can observe the following behavior in each method:\n",
    "- `pandas_equidistant_sample` retains 4 values.\n",
    "- `pandas_equidistant_nearest` duplicates some observations in the equidistant timeseries.\n",
    "- `pandas_equidistant_asfreq` does quite well, but drops some observations near the gap in the original timeseries.\n",
    "- `get_equidistant_series` method misses an observation right after the gap in the original timeseries.\n",
    "- `get_equidistant_series` with `minimize_data_loss=True` fills this gap, using as much data as possible from the original timeseries.\n",
    "\n",
    "The results from the `pandas_equidistant_asfreq` and `get_equidistant_series` methods both work well, but the latter method retains more of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([series, s_pd1, s_pd2, s_pd3, s_pastas2, s_pastas1], axis=1)\n",
    "dfall.columns = [\n",
    "    \"original\",\n",
    "    \"pandas_equidistant_sample\",\n",
    "    \"pandas_equidistant_nearest\",\n",
    "    \"pandas_equidistant_asfreq\",\n",
    "    \"get_equidistant_series (default)\",\n",
    "    \"get_equidistant_series (minimize data loss)\",\n",
    "]\n",
    "dfall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304f555",
   "metadata": {},
   "source": [
    "The following table summarizes the results, showing how many values from the original time series are kept and how many duplicates are contained in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueskept = dfall.apply(values_kept, args=(dfall[\"original\"],))\n",
    "valueskept.name = \"values kept\"\n",
    "duplicates = dfall.apply(n_duplicates)\n",
    "duplicates.name = \"duplicates\"\n",
    "\n",
    "pd.concat([valueskept, duplicates], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1211dc96",
   "metadata": {},
   "source": [
    "#### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries\n",
    "freq = \"2H\"\n",
    "freq2 = \"1H\"\n",
    "idx0 = pd.date_range(\"2000-01-01 18:00:00\", freq=freq, periods=3).tolist()\n",
    "idx1 = pd.date_range(\"2000-01-02 00:00:00\", freq=freq2, periods=10).tolist()\n",
    "idx0 = idx0 + idx1\n",
    "series = pd.Series(index=idx0, data=np.arange(len(idx0), dtype=float))\n",
    "series.iloc[8:10] = np.nan\n",
    "\n",
    "# Create equidistant timeseries\n",
    "s_pd1 = ps.ts.pandas_equidistant_sample(series, freq)\n",
    "s_pd2 = ps.ts.pandas_equidistant_nearest(series, freq)\n",
    "s_pd3 = ps.ts.pandas_equidistant_asfreq(series, freq)\n",
    "s_pastas1 = ps.ts.get_equidistant_series(series, freq, minimize_data_loss=True)\n",
    "s_pastas2 = ps.ts.get_equidistant_series(series, freq, minimize_data_loss=False)\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = series.plot(marker=\"o\", label=\"original\", ms=10)\n",
    "s_pd2.plot(ax=ax, marker=\"x\", ms=10, label=\"pandas_equidistant_nearest\")\n",
    "s_pd3.plot(ax=ax, marker=\"^\", ms=8, label=\"pandas_equidistant_asfreq\")\n",
    "s_pd1.plot(ax=ax, marker=\"+\", ms=16, label=\"pandas_equidistant_sample\")\n",
    "s_pastas1.plot(\n",
    "    ax=ax, marker=\".\", ms=6, label=\"get_equidistant_series (minimize data loss)\"\n",
    ")\n",
    "s_pastas2.plot(ax=ax, marker=\"+\", ms=10, label=\"get_equidistant_series (default)\")\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33b56249",
   "metadata": {},
   "source": [
    "Similar to the previous example, `get_equidistant_timeseries` retains the most data from the original timeseries. In this case both the `pandas_equidistant_asfreq`  and `pandas_equidistant_nearest` methods perform well, but do omit some of the original data at the end of the timeseries or near the gap in the original timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b157111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([series, s_pd1, s_pd2, s_pd3, s_pastas2, s_pastas1], axis=1)\n",
    "dfall.columns = [\n",
    "    \"original\",\n",
    "    \"pandas_equidistant_sample\",\n",
    "    \"pandas_equidistant_nearest\",\n",
    "    \"pandas_equidistant_asfreq\",\n",
    "    \"get_equidistant_series (default)\",\n",
    "    \"get_equidistant_series (minimize data loss)\",\n",
    "]\n",
    "dfall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3f34c90",
   "metadata": {},
   "source": [
    "The following table summarizes the results, showing how many values from the original time series are kept and how many duplicates are contained in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950db6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueskept = dfall.apply(values_kept, args=(dfall[\"original\"],))\n",
    "valueskept.name = \"values kept\"\n",
    "duplicates = dfall.apply(n_duplicates)\n",
    "duplicates.name = \"duplicates\"\n",
    "\n",
    "pd.concat([valueskept, duplicates], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77abd6be",
   "metadata": {},
   "source": [
    "### Creating equidistant time series for fluxes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c3ed03f",
   "metadata": {},
   "source": [
    "# TODO: Ruben\n",
    "\n",
    "- timestamp_weighted_resample, example with monthly pumping data to daily freq (upsampling)\n",
    "- timestamp_weighted_resample, precipitation at 9am-9am -> 12am-12am (shift)\n",
    "- timestamp_weighted_resample, hourly -> daily (downsampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feec8a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artesia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
