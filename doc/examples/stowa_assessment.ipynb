{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pastas as ps\n",
    "from scipy.stats import norm, probplot\n",
    "\n",
    "ps.set_log_level(\"ERROR\")\n",
    "\n",
    "ps.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Time Series Models\n",
    "\n",
    "A frequently asked question is how to evaluate an optimized time series model. This notebook presents methods for model evaluation and illustrates them with real-world examples.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Visual Evaluation](#Visual-Evaluation)\n",
    "- [Fit Statistics](#Fit-Statistics)\n",
    "- [Model Testing](#Model-Testing)\n",
    "- [Model Uncertainty](#Model-Uncertainty)\n",
    "- [Hydrological Evaluation](#Hydrological-Evaluation)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When deciding whether to use or reject a time series model, it is important to first determine the purpose of the model. Based on this purpose, criteria can be established for evaluating the model. \n",
    "\n",
    "This notebook provides an overview of commonly used methods for assessing time series models. For each topic, the most important background information is presented. This document does not offer a complete overview of all research and work done in this area. For readers interested in exploring the topic further, we have included references for deeper study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Evaluation Steps\n",
    "\n",
    "Here we present a number of steps that are commonly used to assess time series models. There is no such thing as a definitive step-by-step plan for model evaluation, so there are also other methods not included in this notebook. The order of the steps is not fixed, but logically structured according to the authors' insights.\n",
    "\n",
    "- **Visual Evaluation:** A good first step is often a visual inspection of the time series model. The behavior of the model is visually inspected, which often provides many valuable insights. The downside of this step is that it can be relatively time-consuming when many models are involved.\n",
    "\n",
    "- **Fit Statistics:** The second step involves assessing the agreement between model and measurements (the fit) based on statistical measures. The advantage of this step is that it provides an objective measure of how well the model matches the data. The downside is that a lot of valuable information is lost when reducing the model’s performance to just a few numbers.\n",
    "\n",
    "- **Model Testing:** The third step is testing the model (often called validation), for example by simulating a period of measurements that was not used in calibration. This tests how well the model performs on data that was not used to optimize the model parameters.\n",
    "\n",
    "- **Model Uncertainty:** The fourth step involves considering the model’s uncertainty. This raises the question: can the model parameters be reliably estimated? Before this uncertainty can be assessed, the model must meet certain statistical requirements. If the model does not meet these requirements, the uncertainty of the parameters cannot be properly evaluated—and therefore cannot be used in the assessment. The parameters may be well estimated, but their uncertainties are not.\n",
    "\n",
    "- **Hydrological Evaluation:** The final step we present here is the hydrological evaluation, where the results of the time series models are compared with hydrological knowledge of the system. This can be done for individual time series models as well as spatially across the results of multiple models. Here, hydrological system knowledge is used to assess the models, but the model results are also used to expand our understanding of the hydrological system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_results_ml(ml):\n",
    "    \"\"\"Plot model simulation and residuals.\n",
    "\n",
    "    Model simulation and observations in top axes, residuals on\n",
    "    second set of axes.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    ml : pastas.Model\n",
    "        plot results for model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : Figure\n",
    "        return figure handle\n",
    "\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), sharex=True, layout=\"tight\")\n",
    "    ml.plot(ax=ax1, legend=False)\n",
    "    ax1.set_ylabel(\"stijghoogte [m NAP]\")\n",
    "    ax1.grid()\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    labels = [\"Head\", \"Simulation\"]\n",
    "    ax1.legend(handles, labels, loc=\"upper left\", ncol=2)\n",
    "    ml.residuals().plot(ax=ax2, color=\"C1\", label=\"residuals\")\n",
    "    ax2.axhline(0.0, linestyle=\"dashed\", color=\"k\", lw=1.5)\n",
    "    ax2.set_ylabel(\"residuen [m]\")\n",
    "    ax2.grid()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def fit_stats_model(ml):\n",
    "    \"\"\"Fit statistics for a model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml : pastas.Model\n",
    "        calculate stats for model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing statistics\n",
    "\n",
    "    \"\"\"\n",
    "    stats = [\n",
    "        \"Mean absolute error (mae)\",\n",
    "        \"Root mean squared error (rmse)\",\n",
    "        \"Sum of the squares of the error (sse)\",\n",
    "        \"Explained variance percentage (evp)\",\n",
    "        \"R-squared (rsq)\",\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(index=stats, columns=[\"value\", \"unit\"])\n",
    "    # fit statistics kunnen in pastas worden opgevraagd met:\n",
    "    # `<model>.stats.<naam statische parameter>()`\n",
    "    df.loc[stats[0], :] = ml.stats.mae(), \"m\"\n",
    "    df.loc[stats[1], :] = ml.stats.rmse(), \"m\"\n",
    "    df.loc[stats[2], :] = ml.stats.sse(), \"m$^2$\"\n",
    "    df.loc[stats[3], :] = ml.stats.evp(), \"%\"\n",
    "    df.loc[stats[4], :] = ml.stats.rsq(), \"-\"\n",
    "\n",
    "    df[\"value\"] = df[\"value\"].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_stats_train_test(ml, train_tmin, train_tmax, test_tmin, test_tmax):\n",
    "    \"\"\"Get statistics for training and testing periods\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    ml : pastas.Model\n",
    "        calculate train/test stats for model\n",
    "    train_tmin : str, pd.Timestamp\n",
    "        start time for training period\n",
    "    train_tmax : str, pd.Timestamp\n",
    "        end time for training period\n",
    "    test_tmin : str, pd.Timestamp\n",
    "        start time for testing period\n",
    "    test_tmax : str, pd.Timestamp\n",
    "        start time for testing period\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing statistics for training/testing\n",
    "        periods\n",
    "\n",
    "    \"\"\"\n",
    "    sim = ml.simulate(tmin=train_tmin, tmax=train_tmax)\n",
    "    obs = ml.oseries.series_original[train_tmin : str(int(train_tmax) - 1)]\n",
    "\n",
    "    stats = [\n",
    "        \"Mean absolute error (mae)\",\n",
    "        \"Root mean squared error (rmse)\",\n",
    "        \"Sum of squares of the error (sse)\",\n",
    "        \"Explained variance percentage (evp)\",\n",
    "        \"R-squared (rsq)\",\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        index=stats,\n",
    "        columns=[\n",
    "            f\"training: {train_tmin}-{train_tmax}\",\n",
    "            f\"test: {test_tmin}-{test_tmax}\",\n",
    "            \"unit\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # statistieken periode 1985 - 2000\n",
    "    df.loc[stats[0], f\"training: {train_tmin}-{train_tmax}\"] = ps.stats.mae(\n",
    "        obs=obs, sim=sim\n",
    "    )\n",
    "    df.loc[stats[1], f\"training: {train_tmin}-{train_tmax}\"] = ps.stats.rmse(\n",
    "        obs=obs, sim=sim\n",
    "    )\n",
    "    df.loc[stats[2], f\"training: {train_tmin}-{train_tmax}\"] = ps.stats.sse(\n",
    "        obs=obs, sim=sim\n",
    "    )\n",
    "    df.loc[stats[3], f\"training: {train_tmin}-{train_tmax}\"] = ps.stats.evp(\n",
    "        obs=obs, sim=sim\n",
    "    )\n",
    "    df.loc[stats[4], f\"training: {train_tmin}-{train_tmax}\"] = ps.stats.rsq(\n",
    "        obs=obs, sim=sim\n",
    "    )\n",
    "\n",
    "    # statistieken periode 2000 - 2015\n",
    "    sim = ml.simulate(tmin=test_tmin, tmax=test_tmax)\n",
    "    obs = ml.oseries.series_original[test_tmin : str(int(test_tmax) - 1)]\n",
    "    df.loc[stats[0], f\"test: {test_tmin}-{test_tmax}\"] = ps.stats.mae(obs=obs, sim=sim)\n",
    "    df.loc[stats[1], f\"test: {test_tmin}-{test_tmax}\"] = ps.stats.rmse(obs=obs, sim=sim)\n",
    "    df.loc[stats[2], f\"test: {test_tmin}-{test_tmax}\"] = ps.stats.sse(obs=obs, sim=sim)\n",
    "    df.loc[stats[3], f\"test: {test_tmin}-{test_tmax}\"] = ps.stats.evp(obs=obs, sim=sim)\n",
    "    df.loc[stats[4], f\"test: {test_tmin}-{test_tmax}\"] = ps.stats.rsq(obs=obs, sim=sim)\n",
    "\n",
    "    df.loc[:, \"unit\"] = [\"m\", \"m\", \"m$^2$\", \"%\", \"-\"]\n",
    "\n",
    "    for icol in df.columns[:-1]:\n",
    "        df[icol] = df[icol].astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set options to display DataFrames in PDF\n",
    "# pd.set_option(\"display.latex.repr\", True)\n",
    "# pd.set_option(\"display.latex.longtable\", True)\n",
    "\n",
    "\n",
    "def _repr_latex_(self):\n",
    "    latex = \"\"\"\\\\begin{center}\n",
    "    {%s}\n",
    "    \\\\end{center}\"\"\" % self.to_latex(float_format=\"{:0.3f}\".format, bold_rows=True)\n",
    "    return latex\n",
    "\n",
    "\n",
    "pd.DataFrame._repr_latex_ = _repr_latex_  # monkey patch pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Evaluation\n",
    "\n",
    "A simple way to evaluate a time series model is by visualizing the results. The model simulation is displayed in a graph alongside the observations. Often, the model residuals are also shown. \n",
    "\n",
    "Based on both graphs, it can be visually assessed whether the simulation aligns well with the measurements, or whether the measurements are poorly approximated. It also allows for evaluating in which periods the model performs well, and in which it does not. \n",
    "\n",
    "For example, is the model able to accurately simulate the peaks and troughs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example of Visual Evaluation 1\n",
    "\n",
    "As an example of a visual evaluation, a time series model has been selected in which the groundwater head is explained based on precipitation and evaporation. The model simulation (blue line) and the measurements (black dots) are shown in the top graph. The residuals (orange line) are shown in the bottom graph.\n",
    "\n",
    "The figure shows that the simulation and the measurements match well. The residuals reveal that the largest differences between model and measurements occur at the extremes: the dips in summer and the peaks in winter. However, the residuals do not show a clear pattern and are evenly distributed around the zero line, indicating that there is no structural error in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head = pd.read_csv(\"data_stowa/hds_basic_model.csv\", parse_dates=True, index_col=0)\n",
    "head = head.iloc[:, 0]  # Convert from DataFrame to Series\n",
    "\n",
    "prec = pd.read_csv(\"data_stowa/prec_basic_model.csv\", parse_dates=True, index_col=0)\n",
    "prec = prec.iloc[:, 0]\n",
    "\n",
    "evap = pd.read_csv(\"data_stowa/evap_basic_model.csv\", parse_dates=True, index_col=0)\n",
    "evap = evap.iloc[:, 0]\n",
    "\n",
    "\n",
    "head.name = \"groundwater head\"\n",
    "prec.name = \"precipitation\"\n",
    "evap.name = \"evaporation\"\n",
    "\n",
    "\n",
    "ml1 = ps.Model(head, name=\"Head\")\n",
    "rm = ps.RechargeModel(\n",
    "    prec, evap, recharge=ps.rch.Linear(), rfunc=ps.Gamma(), name=\"recharge\"\n",
    ")\n",
    "ml1.add_stressmodel(rm)\n",
    "ml1.add_noisemodel(ps.ArNoiseModel())\n",
    "\n",
    "ml1.solve(report=False, fit_constant=True)\n",
    "\n",
    "axes = ml1.plots.results(figsize=(10, 6), adjust_height=True, layout=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example of Visual Evaluation 2\n",
    "\n",
    "The example below shows a time series model where the model simulation (blue line) poorly matches the measurements (black dots). The simulation deviates by as much as 2 meters from the observed groundwater heads. It is not possible to produce reliable simulations with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head2 = pd.read_csv(\"data_stowa/hds_vb_model2.csv\", parse_dates=True, index_col=0)\n",
    "head2 = head2.iloc[:, 0]\n",
    "\n",
    "prec2 = pd.read_csv(\"data_stowa/prec_vb_model2.csv\", parse_dates=True, index_col=0)\n",
    "prec2 = prec2.iloc[:, 0]\n",
    "\n",
    "evap2 = pd.read_csv(\"data_stowa/evap_vb_model2.csv\", parse_dates=True, index_col=0)\n",
    "evap2 = evap2.iloc[:, 0]\n",
    "\n",
    "head2.name = \"Groundwater head\"\n",
    "prec2.name = \"Precipitation\"\n",
    "evap2.name = \"Evaporation\"\n",
    "\n",
    "ml_visual2 = ps.Model(head2, name=\"Head\")\n",
    "rm2 = ps.RechargeModel(\n",
    "    prec2, evap2, recharge=ps.rch.Linear(), rfunc=ps.Exponential(), name=\"recharge\"\n",
    ")\n",
    "ml_visual2.add_stressmodel(rm2)\n",
    "ml_visual2.add_noisemodel(ps.ArNoiseModel())\n",
    "\n",
    "# optimaliseer model\n",
    "ml_visual2.solve(tmin=\"2004\", report=False, fit_constant=True)\n",
    "\n",
    "\n",
    "axes = ml_visual2.plots.results(figsize=(10, 6), adjust_height=True, layout=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Fit Statistics\n",
    "\n",
    "In addition to visual evaluation, model results can also be assessed using statistical parameters. There are various statistical measures that express the fit between simulated and observed groundwater heads numerically. These statistics can be divided into those that express the model error (the residuals) as a single number, and those that attempt to quantify the \"goodness-of-fit\" in a single value.\n",
    "\n",
    "The table below includes several commonly used statistics. For an overview of different fit statistics frequently applied in hydrology, see [Jackson et al. (2019)](#References).\n",
    "\n",
    "It is recommended to consider multiple fit statistics simultaneously when evaluating time series models. Each statistic has its own specific purpose, and no single number can capture all the complexity related to a model's fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- | afkorting         | naam                               | formule                                                                                          | optimale waarde | min          | max      | type            |\n",
    "|:------------------|:-----------------------------------|:------------------------------------------------------------------------------------------------:|:---------------:|:------------:|:--------:|----------------:|\n",
    "| $\\text{SSE}$      | som kwadratische fout              | $$\\sum\\limits_{i=1}^{N}(y_i - \\hat{y_i})^2$$                                                     | 0               | 0         | $\\infty$ | residuën        |\n",
    "| $\\text{MAE}$      | gemiddelde absolute fout           | $$\\sum\\limits_{i=1}^{N}\\frac{ \\left| y_i - \\hat{y_i} \\right| }{N}$$                              | 0               | 0         | $\\infty$ | residuën        |\n",
    "| $\\text{RMSE}$     | wortel kwadratisch gemiddelde fout | $$\\sqrt{ \\sum\\limits_{i=1}^{N} \\frac{ (y_i - \\hat{y_i})^2}{N}}$$                                 | 0               | 0         | $\\infty$ | residuën        |\n",
    "| $\\text{EVP}^{**}$ | verklaarde variantie               | $$\\frac{ \\sigma_y^2 - \\sigma_r^2}{\\sigma_y^2} \\cdot 100$$                                        | 100%            |-$\\infty^*$ | 100      | goodness-of-fit |\n",
    "| $R^2$             | determinatiecoëfficient$^{***}$     | $$1 - \\frac{ \\sum\\limits_{i=1}^{N}(y_i - \\hat{y_i})^2}{\\sum\\limits_{i=1}^{N}(y_i - \\bar{y})^2}$$ | 1               | -$\\infty$ | 1        | goodness-of-fit | -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src=\"data_stowa/fit_stats_table.png\" width=\"800\"> -->\n",
    "![fit statistics table](data_stowa/fit_stats_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$^{*}$ In various time series analysis programs, including Menyanthes and Pastas, the minimum value of the EVP is limited to 0.\n",
    "\n",
    "$^{**}$ [Von Asmuth (2012)](#References)\n",
    "\n",
    "$^{***}$ The coefficient of determination is also often referred to as the Nash-Sutcliffe model efficiency (NSE) coefficient in hydrological models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the formulas above, $N$ is the number of measurements, $y_i$ and $\\hat{y_i}$ are the observed and model-fitted groundwater heads at time $i$, respectively. $\\bar{y}$ is the mean of the observations. $\\sigma_y^2$ and $\\sigma_r^2$ are the variance of the observed groundwater heads and the variance of the residuals $r$, respectively, where $\\sigma_y^2 = \\tfrac{1}{N} \\sum\\limits_{i=1}^{N}\\left(y_i - \\bar{y} \\right)^2$ and $\\sigma_r^2 = \\tfrac{1}{N} \\sum\\limits_{i=1}^{N}\\left(r_i - \\bar{r} \\right)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Between MAE and RMSE\n",
    "\n",
    "The **Mean Absolute Error (MAE)** is the average of the absolute values of all errors. This means that each error is weighted equally. \n",
    "\n",
    "The **Root Mean Squared Error (RMSE)**, on the other hand, squares the errors, giving relatively greater weight to larger errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Between $R^2$ and $\\text{EVP}$\n",
    "\n",
    "The Explained Variance ($\\text{EVP}$) and the Coefficient of Determination ($R^2$) are subtly different. The value of $\\text{EVP}$ is equal to $R^2$ when the mean of the residuals is equal to zero. \n",
    "\n",
    "The optimization of a time series model aims to fit the model such that the mean of the residuals is zero, so in practice, these statistics often have the same value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example of Fit Statistic 1\n",
    "\n",
    "The fit statistics of the first model shown above are listed in the table below. The mean absolute model error is approximately 9 cm. The fit statistics indicate that the model matches the observations well; the explained variance (or EVP) is 92.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bereken statistieken tabel\n",
    "df = fit_stats_model(ml1)\n",
    "\n",
    "# geef tabel weer\n",
    "# df.style.set_precision(3).set_caption(\"Fit statistieken voorbeeld_model_1\")\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example of Fit Statistic 2\n",
    "\n",
    "The fit statistics of the second example model are significantly worse. As already shown visually, the model does not match the observations well. The explained variance (EVP) is only 39.6%, and the mean absolute error (MAE) is as high as 31 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bereken statistieken tabel\n",
    "df = fit_stats_model(ml_visual2)\n",
    "\n",
    "# geef tabel weer\n",
    "# df.style.set_precision(3).set_caption(\"Fit statistieken voorbeeld_model_2\")\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "When more explanatory variables (and thus model parameters) are added to a time series model, the fit generally improves, even if the explanatory variable has little or no actual influence on the groundwater head. The model can use these extra degrees of freedom (parameters) to better fit the measurements. However, adding a non-relevant explanatory variable does not improve the model’s predictive value.\n",
    "\n",
    "The phenomenon where more parameters are added to a model than justified by the data is called **overfitting**. Overfitting can often be recognized by the standard errors of the parameters (see [Model Uncertainty](#Model-Uncertainty)) ([Van Geer, 2012](#References)).\n",
    "\n",
    "There are statistics that compute a relative score based on the model fit, while penalizing for the number of parameters. These help assess whether the addition of parameters has led to a significant model improvement. The **Akaike Information Criterion (AIC)** and the **Bayesian Information Criterion (BIC)** are two examples. Both AIC and BIC are measures of the relative amount of information lost in the model (so-called \"penalized likelihood criteria\"). They are **relative values** and are used to compare different models for the same observation series.\n",
    "\n",
    "If the AIC and BIC decrease after adding an explanatory variable, it means the model has improved (less information is lost). If the AIC and BIC increase, the added parameter has not contributed sufficiently to improving the model.\n",
    "\n",
    "For this notebook, it is only important to understand that the difference between AIC and BIC lies in how they penalize the number of parameters. BIC generally penalizes additional parameters slightly more heavily than AIC.\n",
    "\n",
    "In summary, these statistics can be used to compare different time series models for the same observation well (with different model structures). They provide a relative score for the fit (how well the model matches the data), while penalizing for model complexity. The lower the statistic, the less information is lost in the model, and the better the model may be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: AIC/BIC\n",
    "\n",
    "In this example, we create a time series model for a monitoring point (40CP0393, filter 4) where precipitation and evaporation are linearly combined as an estimate of groundwater recharge. We optimize the model and calculate the EVP, AIC, and BIC. Next, we add the influence of river water level to the time series model. First, we use the exponential response function (2 parameters), and then we repeat the process using the Gamma response function (3 parameters). For both models, we again calculate the EVP, AIC, and BIC. The resulting table shows that adding the river as a stress leads to a significant improvement. The EVP increases substantially, and both AIC and BIC decrease significantly.\n",
    "\n",
    "Based on the EVP, we would conclude that the model with the river and the Gamma response function performs best. The AIC is also lowest for this model, indicating that the improvement in fit quality justifies the addition of an extra parameter. Based on the AIC, we would again select this model as the best. However, the BIC—which penalizes additional parameters more heavily—is lowest for the model with the river and the exponential response function. According to BIC, that model is preferred.\n",
    "\n",
    "Unfortunately, in this case, the statistics do not give a clear-cut answer, so it is up to the user to make a choice. Given the small difference in both AIC and BIC between the time series models with the river, either model is sufficiently good for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    index=[\n",
    "        \"model without river\",\n",
    "        \"model with river (Exponential)\",\n",
    "        \"model with river (Gamma)\",\n",
    "    ],\n",
    "    columns=[\"EVP\", \"AIC\", \"BIC\"],\n",
    "    data=np.nan,\n",
    ")\n",
    "\n",
    "head = pd.read_csv(\"data_stowa/40CP0393-004.csv\", index_col=0, parse_dates=True).iloc[:, 0]\n",
    "prec = (\n",
    "    pd.read_csv(\"data_stowa/RD_Nijmegen.csv\", index_col=0, parse_dates=True).iloc[:, 0] * 1e3\n",
    ")\n",
    "evap = (\n",
    "    pd.read_csv(\"data_stowa/EV24_Deelen.csv\", index_col=0, parse_dates=True).iloc[:, 0] * 1e3\n",
    ")\n",
    "\n",
    "# Maak model o.b.v. grondwateraanvulling\n",
    "ml = ps.Model(head, name=\"40CP0393 (screen 4)\")\n",
    "ml.add_noisemodel(ps.ArNoiseModel())\n",
    "sm = ps.RechargeModel(\n",
    "    prec, evap, name=\"rch\", recharge=ps.rch.Linear(), rfunc=ps.Gamma()\n",
    ")\n",
    "ml.add_stressmodel(sm)\n",
    "ml.solve(tmin=\"2005\", tmax=\"2016\", report=False, fit_constant=True)\n",
    "df.loc[\"model without river\"] = ml.stats.evp(), ml.stats.aic(), ml.stats.bic()\n",
    "\n",
    "# Voeg rivier toe met Exponential respons\n",
    "river = pd.read_csv(\"data_stowa/40CP0393-rivier.csv\", index_col=0, parse_dates=True).iloc[\n",
    "    :, 0\n",
    "]\n",
    "\n",
    "sm2 = ps.StressModel(river, name=\"river\", rfunc=ps.Exponential())\n",
    "ml.add_stressmodel(sm2)\n",
    "ml.solve(tmin=\"2005\", tmax=\"2016\", report=False, fit_constant=True)\n",
    "df.loc[\"model with river (Exponential)\"] = (\n",
    "    ml.stats.evp(),\n",
    "    ml.stats.aic(),\n",
    "    ml.stats.bic(),\n",
    ")\n",
    "\n",
    "# Voeg rivier toe met Gamma respons\n",
    "ml.del_stressmodel(\"river\")\n",
    "sm2 = ps.StressModel(river, name=\"river\", rfunc=ps.Gamma())\n",
    "ml.add_stressmodel(sm2)\n",
    "ml.solve(tmin=\"2005\", tmax=\"2016\", report=False, fit_constant=True)\n",
    "df.loc[\"model with river (Gamma)\"] = ml.stats.evp(), ml.stats.aic(), ml.stats.bic()\n",
    "\n",
    "# Geef tabel weer\n",
    "# df.style.set_precision(3)\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "The purpose of this step is to check whether the model is suitable for its intended purpose. This step is also often referred to as model validation (for a discussion on the correct terminology, see for example [Konikow et al. (1992)](#References)). Cross-validation (in English: 'split-sample testing') is a commonly used method in rainfall-runoff hydrology to test models. It is a way to assess the predictive value of a model. In this method, we split a time series into two parts: a training part and a test part. The part of the measurements we use to calibrate the model is called the training set. We then use the calibrated model to compute a simulation for the second period. This part is called the test set. We compare the test set to the measurements to evaluate whether the model also performs well for the part it was not calibrated on. A time series must be sufficiently long and contain enough measurements to be split into a training part and a test part.\n",
    "\n",
    "The [fit statistics](#Fit-statistics) discussed above can also be used to evaluate the prediction during a test period. For a comprehensive analysis of a set of time series models using this method, including a discussion of the associated fit statistics, see [Knotters (2012)](#References)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Model Test Example 1\n",
    "\n",
    "The example model above was tested by splitting the dataset into two periods. The model was trained on the period 1985–2000 and tested on the period 2000–2015. The results are shown in the graphs below, along with the calculated fit statistics for both periods.\n",
    "\n",
    "The model performs quite well in the test period, which gives confidence in its predictive value. Although the NSE is 3 percentage points lower in the test period compared to the training period, it still remains relatively high at 90.5%. The fit statistics clearly show that the model performs similarly in the test period compared to the training period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tmin, train_tmax = \"1985\", \"2000\"\n",
    "test_tmin, test_tmax = \"2000\", \"2015\"\n",
    "\n",
    "ml_train1 = ml1.copy()\n",
    "ml_train1.solve(tmin=train_tmin, tmax=train_tmax, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), sharex=True, layout=\"tight\")\n",
    "\n",
    "ax1.plot(ml_train1.simulate(tmin=train_tmin, tmax=train_tmax), label=\"model training\")\n",
    "ax1.plot(ml_train1.simulate(tmin=test_tmin, tmax=test_tmax), label=\"model test\")\n",
    "ax1.plot(\n",
    "    ml_train1.oseries.series_original,\n",
    "    ls=\"\",\n",
    "    marker=\".\",\n",
    "    label=\"observations\",\n",
    "    color=\"k\",\n",
    ")\n",
    "ax1.legend(loc=(0, 1), frameon=False, ncol=3, numpoints=3)\n",
    "ax1.grid()\n",
    "fig.suptitle(\"cross validation: example_model_1\")\n",
    "ax1.set_ylabel(\"head [m NAP]\")\n",
    "ax1.axvline(pd.Timestamp(train_tmax), linestyle=\"dashed\", lw=1.5, color=\"k\")\n",
    "\n",
    "\n",
    "ml_train1.residuals(tmin=train_tmin, tmax=train_tmax).plot(\n",
    "    ax=ax2, label=\"residuals training\"\n",
    ")\n",
    "ml_train1.residuals(tmin=test_tmin, tmax=test_tmax).plot(ax=ax2, label=\"residuals test\")\n",
    "\n",
    "ax2.axvline(pd.Timestamp(test_tmin), linestyle=\"dashed\", lw=1.5, color=\"k\")\n",
    "ax2.set_ylabel(\"Residuals [m]\")\n",
    "ax2.legend(loc=(0, 1), frameon=False, ncol=3, numpoints=3)\n",
    "\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = get_stats_train_test(ml_train1, train_tmin, train_tmax, test_tmin, test_tmax)\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "If the model performs well during the test period, then the model derived based on the training period is good enough to predict groundwater heads. This gives confidence that the model performs well, but it does not necessarily mean that the model will also make good predictions in the future. If something changes structurally in the system in the future (e.g., a new abstraction starts pumping outside both selected periods), the model will, of course, not be able to predict that correctly.\n",
    "\n",
    "If the model shows a good fit during the training period but not during the test period, then the model is not a good predictor of groundwater head. This can have several causes. Possible reasons include changes in the system that occurred during the test period, such as the start of a new abstraction or the filling in of a ditch, or the inclusion of an influence in the model that was not yet active during the training period, or overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Model Test Example 2\n",
    "\n",
    "Below is an example of a model with a good fit during the training period and a poor (or less good) fit during the test period. The poor fit is caused by an as yet unexplained trend in the groundwater head. This trend is possibly due to an external influence that was not included during the training of the model. As a result, it is not possible to achieve a good fit for the test period using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head2 = (\n",
    "    pd.read_csv(\n",
    "        \"data_stowa/B32C0609001_1.csv\",\n",
    "        skiprows=16,\n",
    "        parse_dates=[\"Filternummer\"],\n",
    "        date_format=\"%d-%m-%Y\",\n",
    "    )\n",
    "    .set_index(\"Filternummer\")[\"Stand (cm t.o.v. MV)\"]\n",
    "    .multiply(1e-2)\n",
    ")\n",
    "\n",
    "raw = pd.read_csv(\n",
    "    \"data_stowa/etmgeg_260.txt\",\n",
    "    skiprows=47,\n",
    "    parse_dates=[\"YYYYMMDD\"],\n",
    "    date_format=\"%Y%m%d\",\n",
    "    low_memory=False,\n",
    "    na_values=[\"     \"],\n",
    ").set_index(\"YYYYMMDD\")\n",
    "\n",
    "rain = raw[\"   RH\"].multiply(1e3).rename(\"Precipitation\")\n",
    "evap = raw[\" EV24\"].multiply(1e3).rename(\"Evaporation\")\n",
    "\n",
    "ml_cross_validation = ps.Model(head2, name=\"B32C0609 (filter 1)\")\n",
    "\n",
    "# Add a recharge model\n",
    "rch = ps.rch.Linear()\n",
    "rm = ps.RechargeModel(rain, evap, recharge=rch, rfunc=ps.Exponential(), name=\"rch\")\n",
    "ml_cross_validation.add_stressmodel(rm)\n",
    "\n",
    "# train en test periode definieren\n",
    "train_tmin, train_tmax = \"1990\", \"2005\"\n",
    "test_tmin, test_tmax = \"2005\", \"2019\"\n",
    "\n",
    "# Solve the model\n",
    "ml_cross_validation.solve(\n",
    "    tmin=train_tmin, tmax=train_tmax, initial=False, report=False, fit_constant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3), layout=\"tight\")\n",
    "ax.plot(\n",
    "    ml_cross_validation.simulate(tmin=train_tmin, tmax=train_tmax),\n",
    "    label=\"model training\",\n",
    ")\n",
    "ax.plot(\n",
    "    ml_cross_validation.simulate(tmin=test_tmin, tmax=test_tmax), label=\"model test\"\n",
    ")\n",
    "ax.plot(\n",
    "    ml_cross_validation.oseries.series_original,\n",
    "    ls=\"\",\n",
    "    marker=\".\",\n",
    "    label=\"observations\",\n",
    "    color=\"k\",\n",
    ")\n",
    "ax.set_xlim(left=pd.Timestamp(train_tmin))\n",
    "ax.axvline(pd.Timestamp(train_tmax), linestyle=\"dashed\", lw=1.5, color=\"k\")\n",
    "ax.legend(loc=\"lower right\", bbox_to_anchor=(1, 1), frameon=False, ncol=3, numpoints=3)\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Groundwater head [m NAP]\")\n",
    "ax.set_title(\"cross validation: model_3\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Model Uncertainty\n",
    "\n",
    "Every time series model involves a certain level of uncertainty. This uncertainty can be divided into uncertainty about the model structure and uncertainty in the model parameters. In this notebook, only the uncertainty of the model parameters is discussed, but there is a relationship between these two forms of model uncertainty. A large uncertainty in the parameters may indicate a suboptimal model structure, and conversely, a suboptimal model structure often manifests as greater uncertainty in the model parameters. For an explanation of the model structure of time series models, see the [Notebook Model Structure](../model_structuur/model_structuur.ipynb). \n",
    "\n",
    "In time series modeling according to the PIRFICT method, external influences are modeled with response functions, each containing one or more parameters [(Asmuth, 2002)](#References). In addition, a constant and a noise model can also be added to time series models. Time series models can be evaluated based on the calculated uncertainties of these model parameters. It is easy to imagine that a model with parameters that are difficult to estimate (i.e., uncertain parameters) is less reliable than a model whose parameters can be estimated accurately (i.e., with low uncertainty).\n",
    "\n",
    "To assess the uncertainties of the parameters, the series being minimized (the residuals or the noise) must meet certain statistical requirements. A noise model is often applied to ensure that the model satisfies these statistical criteria. The requirements for the residuals/noise are that it:\n",
    "\n",
    "- behaves like white noise with a mean of zero. There is white noise when:\n",
    "  - there is no significant autocorrelation in the noise;\n",
    "  - the noise is homoscedastic, meaning the standard deviation of the noise is constant;\n",
    "  - the noise follows, preferably, a normal statistical distribution.\n",
    "- is not correlated with any explanatory time series.\n",
    "\n",
    "This notebook does not explain the consequences of not meeting these requirements; for that, see the [Notebook Model Calibration](../kalibratie/kalibratie_notebook.ipynb). However, it does show how these requirements can be visually assessed. In addition to visual assessment, there are various diagnostic tests that statistically evaluate whether these requirements are met. The advantage of these tests is that they are more objective than visual inspection. The downside is that they often only work for equidistant time steps and therefore, formally, should not be applied to series with variable time steps. See for example [this notebook on the Pastas website](https://pastas.readthedocs.io/en/latest/examples/003_diagnostic_checking.ipynb.html) for implementation and a more detailed description of such diagnostic tests [(Collenteur et al., 2019)](#References).\n",
    "\n",
    "In summary, the calculated uncertainties of the parameters may be used in further analysis if the statistical requirements mentioned above are met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Reliability of Model Parameters\n",
    "\n",
    "The standard deviation of the model parameters has been calculated for the first example model and is shown in the table below. The standard deviation of the estimated parameters is relatively small compared to the absolute value of the parameters. This suggests that the parameters can be estimated with relatively high accuracy during optimization. However, we do not yet know whether we can use this calculated standard deviation for the various parameters to say something about the model uncertainty. This is because we have not yet assessed whether the model meets the statistical requirements mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = ml1.parameters.loc[:, [\"optimal\", \"stderr\"]]\n",
    "stderr = ml1.parameters.loc[:, \"stderr\"] / ml1.parameters.loc[:, \"optimal\"]\n",
    "params[\"stderr (%)\"] = stderr.abs().apply(\"\\u00b1{:.2%}\".format)\n",
    "params.columns = [\"optimal value\", \"standard deviation\", \"standard deviation (%)\"]\n",
    "params.index.name = \"parameter\"\n",
    "# params.style.set_precision(3)\n",
    "params.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated standard deviation of the parameters can be used to compute a confidence interval. This interval provides insight into the possible model outcomes given the uncertainty in the parameters. The interval is, for example, calculated by taking $N$ samples from the estimated parameter distributions and using those to simulate the groundwater head with the model. The confidence interval is then determined from those $N$ simulations for a given confidence level ($\\alpha$), for example $\\alpha = 0.05$, which corresponds to the 95% confidence interval.\n",
    "\n",
    "In the figure below, the right-hand plot shows the 95% confidence interval calculated for the response to groundwater recharge for example model 1. In the left-hand plot, the prediction interval is shown as a grey band around the model simulation of groundwater head. The prediction interval is the sum of the confidence interval (the uncertainty due to parameter uncertainty) and the standard deviation of the residuals (the uncertainty due to model error).\n",
    "\n",
    "These intervals can be valuable for assessing the model, or even when applying the model, but this requires that the model noise meets the statistical requirements mentioned earlier. In the following sections, we investigate whether the model satisfies those conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = ml1.fit.prediction_interval()\n",
    "fig = plt.figure(figsize=(12, 3), layout=\"tight\")\n",
    "gs = fig.add_gridspec(ncols=2, nrows=1, width_ratios=[2, 1])\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "obs = ml1.oseries.series_original\n",
    "sim = ml1.simulate()\n",
    "\n",
    "obs.plot(\n",
    "    ax=ax1, linestyle=\"\", marker=\".\", color=\"k\", label=\"observation\", x_compat=True\n",
    ")\n",
    "\n",
    "sim.plot(ax=ax1, x_compat=True, label=\"model simulation\")\n",
    "\n",
    "ax1.fill_between(\n",
    "    df.index,\n",
    "    df.iloc[:, 0],\n",
    "    df.iloc[:, 1],\n",
    "    color=\"gray\",\n",
    "    zorder=-1,\n",
    "    alpha=0.5,\n",
    "    label=\"95% prediction interval\",\n",
    ")\n",
    "\n",
    "ax1.set_ylabel(\"head [m NAP]\")\n",
    "ax1.grid()\n",
    "ax1.legend(loc=(0, 1), ncol=3, frameon=False, numpoints=3)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "df = ml1.fit.ci_step_response(\"recharge\", alpha=0.05, n=1000)\n",
    "\n",
    "rch_response = ml1.get_step_response(\"recharge\", add_0=True)\n",
    "\n",
    "\n",
    "rch_response.plot(ax=ax2)\n",
    "ax2.fill_between(\n",
    "    df.index,\n",
    "    df.iloc[:, 0],\n",
    "    df.iloc[:, 1],\n",
    "    color=\"gray\",\n",
    "    zorder=-1,\n",
    "    alpha=0.5,\n",
    "    label=\"95% confidence\",\n",
    ")\n",
    "\n",
    "ax2.grid()\n",
    "ax2.set_xlabel(\"Time [days]\")\n",
    "ax2.set_title(\"recharge response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Condition 1: Autocorrelation\n",
    "\n",
    "Autocorrelation is the correlation of a time series with a time-shifted version of itself. If significant autocorrelation is still present in the noise, the confidence interval of the parameter will be underestimated (see the [Notebook on model calibration](%%) for an example). This type of correlation can be visualized in an autocorrelation plot. In this plot, the horizontal axis shows the time shift (also called 'lag'), and the vertical axis shows the calculated correlation.\n",
    "\n",
    "The time shifts (lags) must correspond to the time step of the model. If the model uses daily time steps, the series must also be shifted by (multiples of) that time step to determine and evaluate the autocorrelation [(Collenteur, 2018)](#References)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example Autocorrelation Plot\n",
    "\n",
    "Autocorrelation has been calculated for the example model, both with and without a noise model. The results are shown in the figures below. The maximum calculated lag is 365 days. A correlation was not calculated for every lag because the time series we are analyzing contains measurements approximately every 14 days.\n",
    "\n",
    "The blue band in the plot represents the 95% confidence interval of the calculated autocorrelation. If the autocorrelation at a given lag falls within the 95% confidence interval, it can be stated with 95% certainty that the autocorrelation at that lag is zero. It is clearly visible that the residuals from the model without a noise model do not meet the autocorrelation requirement. Therefore, the calculated confidence interval for the parameters will not be accurate. In the model with a noise model, we see that there is no significant autocorrelation present in the noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml1.solve(report=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3), layout=\"tight\")\n",
    "ax = ps.plots.acf(\n",
    "    ml1.residuals(),\n",
    "    alpha=0.05,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"Autocorrelation: model1 without noise model\")\n",
    "ax.set_ylim(-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml1.add_noisemodel(ps.ArNoiseModel())\n",
    "ml1.solve(report=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3), layout=\"tight\")\n",
    "ax = ps.plots.acf(ml1.noise(), alpha=0.05, ax=ax)\n",
    "ax.set_ylim(-1.0, 1.0)\n",
    "ax.set_title(\"Autocorrelation: model1 with noisemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition 2: Normal Distribution of Noise\n",
    "\n",
    "Another requirement for white noise is that it follows a statistical distribution, preferably a normal distribution. The distribution of the noise can be visualized using a histogram combined with a normal probability distribution. This can be assessed visually by creating a histogram of the residuals/noise and comparing it with a normal distribution with $\\mu$ equal to the mean of the noise and $\\sigma$ equal to the standard deviation of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Visualizing the Normal Distribution of Noise\n",
    "\n",
    "For the example model, a histogram of the noise has been plotted and compared with the normal distribution. This is shown in the left-hand graph. In the right-hand graph, the same analysis is presented in a different way — a so-called \"probability plot\". If the blue points lie on the black straight line, the noise is normally distributed.\n",
    "\n",
    "Based on these results, it is estimated that the distribution of the noise approximates the normal distribution well enough to approve the model on this aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for normality and add a 'best fit' line\n",
    "bins = 50\n",
    "series = ml1.noise()\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 3), layout=\"tight\")\n",
    "_, bins, _ = ax1.hist(series.values, bins=bins, density=True)\n",
    "y = norm.pdf(bins, series.mean(), series.std())\n",
    "ax1.plot(bins, y, \"k--\")\n",
    "ax1.set_ylabel(\"Probability density\")\n",
    "ax1.set_title(\"Histogram\")\n",
    "\n",
    "# Plot the probability plot\n",
    "probplot(series, plot=ax2, dist=\"norm\", rvalue=True)\n",
    "ax2.get_lines()[0].set_color(\"C0\")\n",
    "ax2.get_lines()[1].set_color(\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition 3: Homoscedasticity\n",
    "\n",
    "The third statistical requirement for white noise is that the noise must be homoscedastic. A time series is homoscedastic when the variance is independent. One way to assess this is by examining the absolute values of the series. If the noise is not homoscedastic (i.e., heteroscedastic), the variance of the noise depends on the groundwater head. This can be visually assessed by plotting the noise against the groundwater head measurements.\n",
    "\n",
    "If the spread of the noise is not consistent across the full range of groundwater head measurements, the noise is heteroscedastic. However, this does not automatically confirm that the noise is homoscedastic. The variance of the noise may also be correlated in other ways, for example, over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Visualizing Homoscedasticity\n",
    "\n",
    "For example model 1, the noise has been plotted against the observations. The spread of the noise appears to be fairly constant across the range of groundwater head measurements. Based on the absolute values, the noise therefore appears to be homoscedastic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 3))\n",
    "ax.plot(ml1.observations(), ml1.noise(), marker=\"o\", linestyle=\" \")\n",
    "ax.set_xlabel(\"measured head [m NAP]\")\n",
    "ax.set_ylabel(\"model noise [m]\")\n",
    "ax.set_title(\"Assessment of homoscedasticity example_model_1\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.2))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "ax.grid(which=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition 4: Correlation of Noise with Explanatory Time Series\n",
    "\n",
    "The final requirement regarding the noise is that it must not be significantly correlated with any of the explanatory series in the time series model. If it is, this indicates that the response function used is apparently not capable of fully describing the behavior of the groundwater head based on the explanatory series. In that case, the uncertainty of the parameters cannot be accurately determined, and the model structure needs to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Hydrological Assessment<a id='hydrologisch-beoordeling'></a>\n",
    "\n",
    "Time series models are widely used for system identification, where the contributions of different influences to changes in groundwater head are estimated. In practice, time series analysis is often applied to an entire monitoring network or to multiple observation wells within an area of interest. Performing a hydrological assessment of individual models, as well as entire sets of time series models, is useful for gaining deeper insight into the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrology<a id='hydrologie'></a>\n",
    "\n",
    "Assessing models based on hydrological aspects can take many forms. The key questions are: \"Does the system behave the way I think it does?\" and \"Are the results I calculate hydrologically plausible?\" In this context, models that do meet expectations are just as interesting as those that do not. For example, consider a model with groundwater recharge and an abstraction rate as explanatory variables. A simple first hydrological assessment is to check whether the groundwater head increases when it rains and decreases when groundwater is extracted. If that is not the case, there is a high chance that the model is not reliable.\n",
    "\n",
    "Time series models can be assessed based on hydrology, but conversely, the model results can also enhance hydrological understanding of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Hydrological Assessment\n",
    "\n",
    "As an example of a hydrological assessment of a time series model, the response to a groundwater abstraction is considered. In the figure below, two different step responses are shown with an uncertainty band. The band, equal to 2 times the standard deviation, is calculated here based on the uncertainty in the gain parameter (the parameter that determines the steady-state effect of the abstraction). In the left-hand graph, the uncertainty of the step response is small—in other words, the parameters can be determined relatively accurately during optimization. In the right-hand graph, this uncertainty is much larger, meaning the influence of the abstraction cannot be estimated accurately through optimization. Note that in this example, a positive step response indicates that the abstraction causes a decrease in groundwater head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfunc = ps.Gamma()\n",
    "p = rfunc.get_init_parameters(\"\")\n",
    "\n",
    "b = rfunc.step(p=p.initial.values)\n",
    "b1 = rfunc.step(p=[1.4, 1, 10])\n",
    "b2 = rfunc.step(p=[0.6, 1, 10])\n",
    "t = np.arange(len(b))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(10, 3), layout=\"tight\")\n",
    "\n",
    "# Plot Links\n",
    "ax[0].fill_between(t, b2, b1, color=\"gray\", alpha=0.5, label=\"95% confidence interval\")\n",
    "ax[0].plot(b, label=\"Optimal\")\n",
    "ax[0].axhline(0, c=\"k\")\n",
    "ax[0].legend(loc=(0, 1), frameon=False, ncol=2)\n",
    "ax[0].set_xlim(0)\n",
    "ax[0].set_xlabel(\"Time [T]\")\n",
    "ax[0].set_ylabel(\"Step response [L]\")\n",
    "ax[0].annotate(\n",
    "    \"\",\n",
    "    xy=(t[-1], b[-1]),\n",
    "    xycoords=\"data\",\n",
    "    xytext=(t[-1], b2[-1]),\n",
    "    textcoords=\"data\",\n",
    "    arrowprops={\"arrowstyle\": \"<->\"},\n",
    ")\n",
    "ax[0].annotate(\n",
    "    \"-2 * $\\sigma_A$\",\n",
    "    xy=(t[-10], 0.8),\n",
    "    xycoords=\"data\",\n",
    "    xytext=(0, 0),\n",
    "    textcoords=\"offset points\",\n",
    ")\n",
    "\n",
    "\n",
    "b1 = rfunc.step(p=[2.2, 1, 10])\n",
    "b2 = rfunc.step(p=[-0.2, 1, 10])\n",
    "ax[1].fill_between(t, b2, b1, color=\"gray\", alpha=0.5, label=\"95% confidence interval\")\n",
    "ax[1].plot(b, label=\"Optimal\")\n",
    "ax[1].axhline(0, c=\"k\")\n",
    "ax[1].legend(loc=(0, 1), frameon=False, ncol=2)\n",
    "ax[1].set_xlabel(\"Time [T]\")\n",
    "ax[1].set_xlim(0)\n",
    "ax[1].annotate(\n",
    "    \"\",\n",
    "    xy=(t[-1], b[-1]),\n",
    "    xycoords=\"data\",\n",
    "    xytext=(t[-1], b2[-1]),\n",
    "    textcoords=\"data\",\n",
    "    arrowprops={\"arrowstyle\": \"<->\"},\n",
    ")\n",
    "ax[1].annotate(\n",
    "    \"-2 * $\\sigma_A$\",\n",
    "    xy=(t[-10], 0.5),\n",
    "    xycoords=\"data\",\n",
    "    xytext=(0, 0),\n",
    "    textcoords=\"offset points\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Estimated step response of an abstraction with low uncertainty (left) and high uncertainty (right).*\n",
    "\n",
    "From a hydrological perspective, the abstraction should cause a decrease in groundwater head. However, in the case of the uncertain model (right), there is more than a 5% chance that the abstraction causes an increase in groundwater head. The uncertainty band is large enough that the step response could also be negative. In that case, we can conclude that this is not hydrologically plausible. The abstraction may not have a significant influence on the groundwater head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Response Memory\n",
    "\n",
    "A response function provides insight into, among other things, the delay with which the groundwater head adjusts to a change in an explanatory variable. A simple example is how long an increase in groundwater head persists after a rainfall event. The time it takes for the effect of a change in an explanatory variable on the groundwater head to become negligibly small is often referred to as the memory of the response.\n",
    "\n",
    "If the response memory is longer than the length of the time series on which the time series model is calibrated, then the time series is not long enough to accurately estimate such a delayed response. In that case, the time series model could be rejected on that basis.\n",
    "\n",
    "Another way to assess the memory of the response is from a hydrological perspective. Based on hydrological system knowledge, it may be possible to define limits for the expected memory of the response, or by comparing multiple models, it can be evaluated whether the response memory is plausible. This latter example is a form of spatial assessment, which is discussed later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Determining the Memory of the Response Function\n",
    "\n",
    "The memory of the response function cannot be determined by identifying the point where the response equals zero. Most response functions never actually reach zero but instead approach zero as $t \\rightarrow \\infty$. For this reason, a common measure of memory is the time it takes for 95% of the response to dissipate. This is visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm = ml1.stressmodels[\"recharge\"]\n",
    "resp_func = sm.rfunc\n",
    "t95 = resp_func.get_tmax(ml1.get_parameters(\"recharge\"), cutoff=0.95)\n",
    "print(f\"Memory (t_95) = {t95:.0f} days\")\n",
    "\n",
    "ax = ml1.plots.block_response(figsize=(10, 3), layout=\"tight\")\n",
    "ylim = ax.get_ylim()\n",
    "ax.vlines(t95, -100, 100, ls=\":\", color=\"k\", label=\"t95\", lw=1.5)\n",
    "\n",
    "block_response = sm.rfunc.block(ml1.get_parameters(\"recharge\"))\n",
    "\n",
    "ax.fill_between(\n",
    "    range(1, len(block_response) + 1),\n",
    "    0,\n",
    "    block_response,\n",
    "    hatch=\"/\",\n",
    "    where=range(len(block_response)) < t95,\n",
    "    alpha=0.5,\n",
    "    color=\"green\",\n",
    "    label=\"95%\",\n",
    ")\n",
    "\n",
    "ax.fill_between(\n",
    "    range(1, len(block_response) + 1),\n",
    "    0,\n",
    "    block_response,\n",
    "    where=range(len(block_response)) > t95,\n",
    "    hatch=\"o\",\n",
    "    alpha=0.5,\n",
    "    color=\"yellow\",\n",
    "    label=\"5%\",\n",
    ")\n",
    "ax.set_ylim(0, ylim[1])\n",
    "ax.legend(loc=\"lower right\", bbox_to_anchor=(1.0, 1.0), frameon=False, ncol=4)\n",
    "ax.set_title(\"block response recharge\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Memory 1\n",
    "\n",
    "Below, the block response and model results of the example model are plotted in a single figure. In this model, the length of the time series is several times longer than the memory of the response function. Therefore, we can conclude that the time series is sufficiently long to estimate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get response function\n",
    "sm = ml1.stressmodels[\"recharge\"]\n",
    "resp_func = sm.rfunc\n",
    "fig, ax = plt.subplots(figsize=(10, 3), layout=\"tight\")\n",
    "block_resp = resp_func.block(ml1.get_parameters(\"recharge\"), cutoff=0.999999)\n",
    "\n",
    "# plot response function\n",
    "ax.plot(\n",
    "    pd.date_range(ml1.settings[\"tmin\"], periods=len(block_resp)),\n",
    "    block_resp,\n",
    "    label=\"block response\",\n",
    "    color=\"orange\",\n",
    "    lw=3,\n",
    ")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"block response recharge\")\n",
    "# ax.set_ylim(0,6)\n",
    "\n",
    "\n",
    "# plot t95 response functie\n",
    "t95 = ml1.stressmodels[\"recharge\"].rfunc.get_tmax(\n",
    "    ml1.get_parameters(\"recharge\"), cutoff=0.95\n",
    ")\n",
    "t95_dt = ml1.settings[\"tmin\"] + pd.Timedelta(days=t95)\n",
    "ylim = ax.get_ylim()\n",
    "ax.vlines(t95_dt, -100, 100, ls=\":\", color=\"C3\", label=\"t95\", lw=1.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.legend(loc=(0, 1), frameon=False, ncol=2)\n",
    "\n",
    "# plot model results\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(ml1.simulate(), label=\"simulation\")  # , lw=0.2)\n",
    "ax2.plot(ml1.oseries.series_original[:], marker=\".\", ls=\"\", color=\"k\", label=\"meting\")\n",
    "ax2.set_ylabel(\"Groundwater head [m NAP]\")\n",
    "# ax2.set_ylim(28,31)\n",
    "ax2.legend(\n",
    "    bbox_to_anchor=(1, 0.95), loc=\"lower right\", ncol=2, frameon=False, numpoints=3\n",
    ")\n",
    "_ = ax.set_title(\"Model period and blockresponse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Memory 2\n",
    "\n",
    "For another example model, the block response and model results are also plotted in a single figure. In this model, the length of the time series is shorter than the memory of the response function. If the response is longer than the measurement series, it cannot be determined from the data whether the response is justifiably that long. In this case, it can be concluded that the time series is not long enough to derive a reliable time series model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head = pd.read_csv(\"data_stowa/hds_vb_geheugen.csv\", parse_dates=True, index_col=0)\n",
    "head = head.iloc[:, 0]\n",
    "\n",
    "rech = pd.read_csv(\"data_stowa/recharge_vb_geheugen.csv\", parse_dates=True, index_col=0)\n",
    "rech = rech.iloc[:, 0]\n",
    "\n",
    "head.name = \"groundwater head\"\n",
    "rech.name = \"recharge\"\n",
    "\n",
    "ml_example = ps.Model(head, name=\"B52C0508-002\")\n",
    "sm = ps.StressModel(rech, rfunc=ps.Gamma(), name=\"recharge\", settings=\"prec\")\n",
    "ml_example.add_stressmodel(sm)\n",
    "ml_example.add_noisemodel(ps.ArNoiseModel())\n",
    "ml_example.solve(report=False, fit_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get response function\n",
    "sm = ml_example.stressmodels[\"recharge\"]\n",
    "resp_func = sm.rfunc\n",
    "fig, ax = plt.subplots(figsize=(10, 3), layout=\"tight\")\n",
    "block_resp = resp_func.block(ml_example.get_parameters(\"recharge\"), cutoff=0.97)\n",
    "\n",
    "# plot response function\n",
    "ax.plot(\n",
    "    pd.date_range(ml_example.settings[\"tmin\"], periods=len(block_resp)),\n",
    "    block_resp,\n",
    "    label=\"block response\",\n",
    "    color=\"orange\",\n",
    "    lw=3,\n",
    ")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"block response recharge\")\n",
    "\n",
    "# plot t95 of the response function\n",
    "t95 = ml_example.stressmodels[\"recharge\"].rfunc.get_tmax(\n",
    "    ml_example.get_parameters(\"recharge\"), cutoff=0.95\n",
    ")\n",
    "t95_dt = ml_example.settings[\"tmin\"] + pd.Timedelta(days=t95)\n",
    "ylim = ax.get_ylim()\n",
    "ax.vlines(t95_dt, -100, 100, ls=\":\", color=\"C3\", label=\"t95\", lw=1.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.legend(loc=(0, 1), frameon=False, ncol=2)\n",
    "ax.set_xlim(pd.Timestamp(\"2013-01-01\"), pd.Timestamp(\"2015-12-31\"))\n",
    "\n",
    "# plot model results\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(ml_example.simulate(), label=\"simulation\")\n",
    "ax2.plot(\n",
    "    ml_example.oseries.series_original,\n",
    "    marker=\".\",\n",
    "    ls=\"\",\n",
    "    color=\"k\",\n",
    "    label=\"observation\",\n",
    ")\n",
    "ax2.set_ylabel(\"head [m NAP]\")\n",
    "ax2.legend(\n",
    "    bbox_to_anchor=(1, 0.95), loc=\"lower right\", ncol=2, frameon=False, numpoints=3\n",
    ")\n",
    "ax2.set_xlim(pd.Timestamp(\"2013-01-01\"), pd.Timestamp(\"2015-12-31\"))\n",
    "\n",
    "_ = ax.set_title(\"model period and block response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Net Precipitation\n",
    "\n",
    "The influence of precipitation and evaporation is often incorporated as the net precipitation, calculated using the following formula:\n",
    "\n",
    "$$ \\text{R} = \\text{P} + f \\cdot \\text{E}$$\n",
    "\n",
    "where $\\text{R}$ is the net precipitation, $\\text{P}$ is the precipitation, and $\\text{E}$ is the evaporation. In the Netherlands, reference crop evaporation is commonly used as a measure of potential evaporation. The actual evaporation, i.e., how much actually evaporates, is usually unknown. In the formula above, the actual evaporation is calculated by multiplying the potential evaporation by the evaporation factor $f$. The evaporation factor is often optimized within a time series model.\n",
    "\n",
    "The optimized value of the evaporation factor can be evaluated from a hydrological perspective. The following interpretations can be given to the optimized value:\n",
    "\n",
    "- $f < -2$: the net precipitation is calculated using an actual evaporation that is more than twice the reference crop evaporation.\n",
    "- $-2 < f < 0$: the net precipitation is calculated by scaling the evaporation by a certain factor.\n",
    "- $f = 0$: the precipitation alone is sufficient to explain the groundwater head. Evaporation is not included in the time series model.\n",
    "- $f > 0$: the evaporation factor is positive, which would mean that evaporation leads to a rise in the groundwater head. This is not hydrologically plausible.\n",
    "\n",
    "In addition to evaluating the optimized value, it is also possible to define boundary values within which a given parameter may be optimized. This allows physical constraints to be imposed on the model. For the evaporation factor, the following bounds are often applied:\n",
    "- $f < 0$: evaporation should result in a decrease in groundwater head, so the evaporation factor must be less than zero.\n",
    "- $f > -2$: the actual evaporation used in the net precipitation calculation must not be more than twice the reference crop evaporation. Reference crop evaporation is based on a well-watered and well-nourished crop, so it is illogical for actual evaporation to be more than twice that amount.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaporation Factor and Crop Coefficient\n",
    "\n",
    "In many groundwater models, a crop coefficient is used to convert reference crop evaporation into actual evaporation. This coefficient is often compared to the evaporation factor used in time series models. While there are certainly similarities between the two, there are also some important differences:\n",
    "\n",
    "- The evaporation factor in a time series model is optimized together with other parameters. It can be correlated with other model parameters. For example, a slightly overestimated drainage base might be compensated by a lower evaporation factor. As a result, the optimized value of the evaporation factor only has meaning in combination with the other model parameters and cannot be directly compared to a physical crop coefficient.\n",
    "\n",
    "- The actual evaporation (or transpiration) of a crop varies significantly throughout the year, depending on the season and the crop's growth characteristics. Therefore, the crop coefficient is not constant. In many time series models, however, the evaporation factor is assumed to be constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Evaporation Factor\n",
    "\n",
    "The time series from the base model were used to illustrate the effect of the evaporation factor on the model results. First, the net precipitation is shown for different evaporation factors. Below that, the model results are displayed for the same model, each time optimized with a different fixed value for the evaporation factor.\n",
    "\n",
    "Several observations can be made from the graphs:\n",
    "- With an evaporation factor of $f = 0$, evaporation is not included; the model is optimized solely based on precipitation. The fit between the modeled and observed groundwater heads is poor.\n",
    "- With an evaporation factor of $f = -1.3$, the best fit is achieved. This is the optimal value of the evaporation factor from the original model.\n",
    "- With an evaporation factor of $f = -2.0$, evaporation weighs twice as heavily as precipitation, and the fit between the model simulation and the measurements is still quite good.\n",
    "- With an unrealistic evaporation factor of $f = -10.0$, evaporation weighs ten times more than precipitation. Because the actual evaporation is extremely overestimated, the effect of precipitation is barely visible in the simulated series.\n",
    "\n",
    "Finally, for all models, the optimized drainage base is also shown. A correlation with the evaporation factor can be observed: when the evaporation factor is fixed at a lower value during optimization, this is compensated by a higher drainage base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sla optimale verdampingsfactor op\n",
    "f_opt = ml1.parameters.loc[\"recharge_f\", \"optimal\"]\n",
    "\n",
    "neerslag, verdamping = ml1.stressmodels[\"recharge\"].stress\n",
    "\n",
    "# berekenen en plotten verdampingsfactoren\n",
    "verdampingsfactoren = [-1e-10, ml1.parameters.loc[\"recharge_f\", \"optimal\"], -2.0, -10.0]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    figsize=(10, 6),\n",
    "    nrows=len(verdampingsfactoren),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    layout=\"tight\",\n",
    ")\n",
    "for i, f in enumerate(verdampingsfactoren):\n",
    "    neerslagoverschot = neerslag.series + f * verdamping.series\n",
    "    neerslagoverschot.plot(ax=axes[i], label=f\"f={f:.2f}\")\n",
    "    axes[i].grid()\n",
    "    axes[i].legend(loc=1)\n",
    "    axes[i].set_ylabel(\"Head (m)\")\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "axes[0].set_title(\"Net precipitation with different evaporation factors (f)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neerslag, verdamping = ml1.stressmodels[\"recharge\"].stress\n",
    "\n",
    "# berekenen en plotten verdampingsfactoren\n",
    "verdampingsfactoren = [-1e-10, f_opt, -2.0, -10.0]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    figsize=(10, 6),\n",
    "    nrows=len(verdampingsfactoren),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    layout=\"tight\",\n",
    ")\n",
    "results_df = pd.DataFrame(\n",
    "    index=pd.Index(\n",
    "        [f\"{i:.1f}\" for i in ([0.0] + verdampingsfactoren[1:])],\n",
    "        name=\"verdampingsfactor\",\n",
    "    ),\n",
    "    columns=[\"drainagebasis (m NAP)\", \"EVP (%)\"],\n",
    ")\n",
    "\n",
    "for i, (idx, f) in enumerate(zip(results_df.index, verdampingsfactoren)):\n",
    "    ml1.set_parameter(\n",
    "        \"recharge_f\", initial=f, optimal=f, pmax=1.0, pmin=-1000.0, vary=False\n",
    "    )\n",
    "    ml1.solve(report=False)\n",
    "    ml1.plot(ax=axes[i], label=f\"f={f:.1f}\", legend=False)\n",
    "    axes[i].grid()\n",
    "\n",
    "    results_df.loc[idx, \"drainagebasis (m NAP)\"] = (\n",
    "        f\"{ml1.parameters.loc['constant_d', 'optimal']:.2f}\"\n",
    "    )\n",
    "    results_df.loc[idx, \"EVP (%)\"] = f\"{ml1.stats.evp():.2f}\"\n",
    "\n",
    "    #     print(f'modelsimulatie met verdampingsfactor f={f:.1f} heeft een '\n",
    "    #           f'geoptimaliseerde drainagebasis van '\n",
    "    #           f'{ml1.parameters.loc[\"constant_d\", \"optimal\"]:.2f} m')\n",
    "    handles, labels = axes[i].get_legend_handles_labels()\n",
    "    labels[1] = labels[1].replace(\"Simulation\", f\"Simulation with f={f:.1f}\")\n",
    "    axes[i].legend(handles[1:], labels[1:])\n",
    "    axes[i].set_ylabel(\"Head (m)\")\n",
    "    axes[i].set_xlabel(\"Time\")\n",
    "    axes[i].xaxis.set_major_locator(mpl.dates.YearLocator(4))\n",
    "    axes[i].xaxis.set_minor_locator(mpl.dates.YearLocator(1))\n",
    "axes[0].set_title(\"Model simulation with evaporation factor\")\n",
    "axes[-1].set_xlim(axes[-2].get_xlim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Correlation\n",
    "\n",
    "When optimizing time series models, it is also possible to examine the correlations between parameters. If a model contains parameters that are 100% correlated, a change in one parameter can be compensated by a change in the correlated parameter, while the model fit remains virtually the same. High parameter correlation is not a problem for the reliability of the time series model. After all, the model always uses the combination of these parameters to perform a simulation. However, high correlations mean that the absolute value of the optimized parameter should not be considered independently of the absolute value of the correlated parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Parameter Correlations\n",
    "\n",
    "The evaporation factor and the drainage base are parameters that are often strongly correlated. In the model from the previous example, the correlation between the evaporation factor and the drainage base is -0.98. In the previous example, the models were each calculated using a different evaporation factor, and in the results of this model, we can clearly observe the effect of the high correlation with the drainage base. \n",
    "\n",
    "The table below shows the values of the evaporation factor, the optimized drainage base, and the NSE. It is clearly visible that as the evaporation factor increases, the optimized drainage base decreases. It is also apparent that the NSE decreases by only 1.5 percentage points compared to the optimal model when the evaporation factor is set to -2.0. The value of the drainage base increases to compensate for this increase in evaporation. In this case, the absolute values of the drainage base and the evaporation factor cannot be interpreted independently of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Spatial Assessment\n",
    "\n",
    "In many studies, time series analysis is applied to multiple groundwater head monitoring points. These studies may aim, for example, to determine where groundwater heads can be well explained by groundwater recharge, or to investigate the influence of a drinking water abstraction on groundwater levels—among many other possible objectives. In such studies, it is useful to perform a spatial assessment of the results. For examples of spatial analyses, see for instance [Baggelaar (1988)](#References), [Asmuth (2012)](#References), and [Berendrecht (2016)](#References). This aspect is illustrated in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Example: Hydrological Spatial Assessment\n",
    "\n",
    "An example of spatial assessment of time series models is provided by [Collenteur et al. (2019)](#References). In that study, time series models were developed for observation wells within a radius of ±5 km around a drinking water abstraction site operated by Brabant Water near Seppe. These time series models included precipitation, evaporation, and the abstraction rate of the Seppe site as explanatory variables. The models were then optimized.\n",
    "\n",
    "In the figure below, the calculated steady-state influences (also known as the 'gain') of the Seppe abstraction are plotted against the distance between the observation wells and the abstraction location. A distinction is made between wells in the first and second aquifer layers. The vertical bars indicate the uncertainty, corresponding to twice the standard deviation of the parameter. The steady-state influence is calculated for an abstraction rate of 1 million m³/year. The figure also shows the theoretical steady-state influence of the abstraction as a function of distance, calculated with a two-layer analytical element groundwater model [(Bakker et al., 2003)](#References), serving as an additional check on the influence estimated by the time series models.\n",
    "\n",
    "![drawdown_example](data_stowa/drawdown_screenshot.png)\n",
    "\n",
    "*Calculated steady-state influence of the Seppe abstraction as a function of distance at an abstraction rate of 1 Mm³/year (source: Collenteur et al. (2019))*\n",
    "\n",
    "Each time series model is independent of the others; each model estimates the contributions of precipitation, evaporation, and abstraction to changes in groundwater head based on local measurements. The calculated pattern of greater drawdown near the abstraction site aligns well with the theoretical influence of pumping. The difference between the first and second aquifer layers is also clearly visible in the time series model results. Moreover, the results show good agreement with those from a simple groundwater model.\n",
    "\n",
    "These independent models appear to be well suited to estimate the influence of the drinking water abstraction on groundwater heads. Based on this spatial assessment, it is concluded that the time series models can be applied for further analysis of the abstraction’s impact. A spatial hydrological review of the results from multiple time series models can be a valuable part of the assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Baggelaar, P.K. (1988) Tijdreeksanalyse bij verlagingsonderzoek: principe en voorbeeld. H $_2$ O (21) nr. 15\n",
    "- Bakker, M., and O.D.L. Strack (2003). Analytic Elements for Multiaquifer Flow. Journal of Hydrology, 271(1-4), 119-129.\n",
    "- Berendrecht, W.L., and F.C. Van Geer (2016) A dynamic factor modeling framework for analyzing multiple groundwater head series simultaneously. Journay of Hydrology, Vol. 536, 50-60.\n",
    "- Collenteur, R.A. (2018) Over autocorrelatie van tijdreeksmodellen met niet-equidistante tijdstappen, Artesia, Schoonhoven, Nederland.\n",
    "- Collenteur, R.A., M. Bakker, R. Caljé, S.A. Klop, F. Schaars (2019) Pastas: Open Source Software for the Analysis of Groundwater Time Series. Groundwater, Vol. 57, No. 6, 877–885\n",
    "- van Geer, F. (2012) Tijdreeksanalyse: Introductie en aandachtspunten. Stromingen 18, nummer 2.\n",
    "- Jackson et al. (2019) Introductory overview: Error metrics for hydrological modelling - A review of common practices and an open source library to facilitate use and adoption. Environmental Modelling & Software 119, 32-48.\n",
    "- Knotters, M. (2012) Validatie van tijdreeksmodellen voor de grondwaterstand. Stromingen 18, nummer 2.\n",
    "- Konikow, L.F. and J.D. Bredehoeft (1992) Groundwater models cannot be validated. Advances in Water Resources, Vol. 15, No. 1, 75-83\n",
    "- Von Asmuth, J.R., K. Maas, and M.F.P. Bierkens (2002) Transfer function-noise modeling in continuous time using predefined impulse response functions, Water Resour. Res., 38(12), 1287.\n",
    "- Von Asmuth, J.R., K. Maas, M. Knotters, M.F.P. Bierkens, M. Bakker, T.N. Olsthoorn, D.G. Cirkel, I. Leunk, F. Schaars, and D.C. von Asmuth (2012) Software for hydrogeologic time series analysis, interfacing data with physical insight, Environmental Modelling & Software, 38(0), 178-190."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "D.A. Brakenhoff"
   },
   {
    "name": "O.N. Ebbens"
   }
  ],
  "kernelspec": {
   "display_name": "test-examples (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "title": "Beoordeling Tijdreeksmodellen",
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
